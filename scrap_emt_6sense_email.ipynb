{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 HTML files\n",
      "URL count: 0\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz Connectw list part 1_s0aj0jdasjczxncanscjasncnzxmn.html\n",
      "URL count: 1\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz ConnectW pt 2_ds9ajdjasjcxzcasczx0kckzx.html\n",
      "URL count: 2\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_0askd0akczjx9jcaj9jsczxmczxmn.html\n",
      "URL count: 3\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_8ahd8ashd7gasgzxjcbnasmz90zxcz.html\n",
      "URL count: 4\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_9asd9jasda9jd9asdaj9dja.html\n",
      "URL count: 5\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_as9dj9asjd9asj9dja9sjd9jasj.html\n",
      "URL count: 6\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_ASd8has7hczxh9jas9jczxnca9ssjczxcnzxmmnzxzcz.html\n",
      "URL count: 7\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_sa9djashczxhhzxnnzxn.html\n",
      "URL count: 8\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_sa9jd9asjd9ja9j.html\n",
      "URL count: 9\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_SA9jdas7g7cgzguasbcnzxbq7a7sachhzx.html\n",
      "URL count: 10\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazz NJ Schools complete alert_sad8has7hdcgz66czgggzxvcbzxb.html\n",
      "URL count: 11\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - eMazzanti ARMA List Aug 2021_Sdja9dja9sjdjacjzxmcmzmxcmx.html\n",
      "URL count: 12\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE -  eMazzanti NJ Manufacturers_sa8hd8ashhvadvbbzcnbnbn.html\n",
      "URL count: 13\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE ARMA NY list 3 alert_a9sjd8ashd7gasgczbxbcbz.html\n",
      "URL count: 14\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE eMazz ARMA NE List 2_sa9jd9ajsjcxzcasmncmzxnnzxcxzza12d.html\n",
      "URL count: 15\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE eMazz Hawaii Directory_0asjd0jacjxzkckas0kcmxznannnv.html\n",
      "URL count: 16\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE emazz LegalTech List_Dsa8hda78sh7gczxggczxbzbb.html\n",
      "URL count: 17\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE eMazz Retail List_dsa9jd9asjdja9jaaazzcx.html\n",
      "URL count: 18\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE eMazzanti Hudson Directory_9asjd9ajsd8has7gczx7hbxzcbb.html\n",
      "URL count: 19\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE eMazzanti IACC list_Ds9ajd9asjjcascnzxncasnjk.html\n",
      "URL count: 20\n",
      "c:\\eMazzanti\\6sense\\6sense Hot Accounts USCAN - NE eMazzanti Manufacturers NJ Prospect Segment_sa9jd9asjjazxcncnxzncxzczzz.html\n",
      "c:\\eMazzanti\\6sense\\_master_files\\\\17-Aug-2023\n",
      "File 6sense_master_file_17-Aug-2023.xlsx saved in c:\\eMazzanti\\6sense\\_master_files\\\\17-Aug-2023\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date added</th>\n",
       "      <th>Activity date</th>\n",
       "      <th>Email title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Website</th>\n",
       "      <th>Location</th>\n",
       "      <th>Buying stage</th>\n",
       "      <th>Profile fit</th>\n",
       "      <th>Account reach</th>\n",
       "      <th>Watchguard visitors</th>\n",
       "      <th>Watchguard links</th>\n",
       "      <th>Keyword1</th>\n",
       "      <th>Keyword2</th>\n",
       "      <th>Keyword3</th>\n",
       "      <th>Keyword4</th>\n",
       "      <th>Keyword5</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>NE eMazz Connectwise A to J list</td>\n",
       "      <td>CIO Solutions</td>\n",
       "      <td>ciosolutions.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 Web Visit - 0 known contact , 1 anonymous</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>eMazzanti NJ Manufacturers</td>\n",
       "      <td>Grant Industries</td>\n",
       "      <td>grantinc.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Crowdstrike</td>\n",
       "      <td>endpoint protection</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2 Keywords - 2 times researched by 1 anonymous...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>eMazzanti NJ Manufacturers</td>\n",
       "      <td>SEEK Asia</td>\n",
       "      <td>seekasia.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>palo alto networks</td>\n",
       "      <td>network security</td>\n",
       "      <td>network security management</td>\n",
       "      <td>virtual firewall</td>\n",
       "      <td>security services</td>\n",
       "      <td>5 Keywords - 10 times researched by 1 anonymou...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>The Andrew W. Mellon Foundation</td>\n",
       "      <td>mellon.org</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>LastPass</td>\n",
       "      <td>security vulnerability</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2 Keywords - 7 times researched by 1 anonymous...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>City Of Pflugerville</td>\n",
       "      <td>pflugervilletx.gov</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>security services</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 Keyword - 1 time researched by 1 anonymous u...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>NE Emazz Connectwise K to Z List</td>\n",
       "      <td>The Spence School</td>\n",
       "      <td>spenceschool.org</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Okta</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>SHI</td>\n",
       "      <td>NordVPN</td>\n",
       "      <td>Zyxel</td>\n",
       "      <td>28 Keywords - 128 times researched by 65 anony...</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>NE eMazzanti ARMA NYC List3</td>\n",
       "      <td>Texas County &amp; District Retirement System</td>\n",
       "      <td>tcdrs.org</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>SHI</td>\n",
       "      <td>NordVPN</td>\n",
       "      <td>Okta</td>\n",
       "      <td>Ruckus</td>\n",
       "      <td>47 Keywords - 233 times researched by 130 anon...</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>Texas County &amp; District Retirement System</td>\n",
       "      <td>tcdrs.org</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>SHI</td>\n",
       "      <td>NordVPN</td>\n",
       "      <td>Okta</td>\n",
       "      <td>Ruckus</td>\n",
       "      <td>47 Keywords - 233 times researched by 130 anon...</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>NE eMazzanti ARMA Northeast list2</td>\n",
       "      <td>Ivey Barnum&amp;O'Mara</td>\n",
       "      <td>ibolaw.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Decision</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Okta</td>\n",
       "      <td>Microsoft Authenticator</td>\n",
       "      <td>McAfee</td>\n",
       "      <td>NordVPN</td>\n",
       "      <td>palo alto networks</td>\n",
       "      <td>68 Keywords - 514 times researched by 244 anon...</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>17-Aug-2023</td>\n",
       "      <td>Aug 13, 2023</td>\n",
       "      <td>NE eMazzanti IACC List</td>\n",
       "      <td>Frederick Wildman &amp; Sons</td>\n",
       "      <td>frederickwildman.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partner Intent Activities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date added  Activity date                          Email title  \\\n",
       "0    17-Aug-2023  Aug 13, 2023     NE eMazz Connectwise A to J list    \n",
       "156  17-Aug-2023  Aug 13, 2023           eMazzanti NJ Manufacturers    \n",
       "151  17-Aug-2023  Aug 13, 2023           eMazzanti NJ Manufacturers    \n",
       "149  17-Aug-2023  Aug 13, 2023         ARMA NYC List 1  August 2021    \n",
       "148  17-Aug-2023  Aug 13, 2023         ARMA NYC List 1  August 2021    \n",
       "..           ...            ...                                  ...   \n",
       "36   17-Aug-2023  Aug 13, 2023     NE Emazz Connectwise K to Z List    \n",
       "162  17-Aug-2023  Aug 13, 2023          NE eMazzanti ARMA NYC List3    \n",
       "141  17-Aug-2023  Aug 13, 2023         ARMA NYC List 1  August 2021    \n",
       "172  17-Aug-2023  Aug 13, 2023    NE eMazzanti ARMA Northeast list2    \n",
       "221  17-Aug-2023  Aug 13, 2023               NE eMazzanti IACC List    \n",
       "\n",
       "                                           Name               Website  \\\n",
       "0                                CIO Solutions       ciosolutions.com   \n",
       "156                           Grant Industries           grantinc.com   \n",
       "151                                  SEEK Asia           seekasia.com   \n",
       "149            The Andrew W. Mellon Foundation             mellon.org   \n",
       "148                       City Of Pflugerville     pflugervilletx.gov   \n",
       "..                                          ...                   ...   \n",
       "36                           The Spence School       spenceschool.org   \n",
       "162  Texas County & District Retirement System              tcdrs.org   \n",
       "141  Texas County & District Retirement System              tcdrs.org   \n",
       "172                         Ivey Barnum&O'Mara             ibolaw.com   \n",
       "221                   Frederick Wildman & Sons   frederickwildman.com   \n",
       "\n",
       "            Location    Buying stage Profile fit Account reach  \\\n",
       "0     United States        Decision    Moderate        Medium    \n",
       "156   United States       Awareness      Strong           Low    \n",
       "151   United States       Awareness    Moderate           Low    \n",
       "149   United States       Awareness    Moderate           Low    \n",
       "148   United States       Awareness      Strong           Low    \n",
       "..               ...             ...         ...           ...   \n",
       "36    United States   Consideration      Strong           Low    \n",
       "162   United States   Consideration      Strong           Low    \n",
       "141   United States   Consideration      Strong           Low    \n",
       "172   United States        Decision    Moderate           Low    \n",
       "221   United States       Awareness    Moderate           Low    \n",
       "\n",
       "     Watchguard visitors Watchguard links             Keyword1  \\\n",
       "0                      0             None                        \n",
       "156                    0             None          Crowdstrike   \n",
       "151                    0             None   palo alto networks   \n",
       "149                    0             None             LastPass   \n",
       "148                    0             None    security services   \n",
       "..                   ...              ...                  ...   \n",
       "36                     0             None                 Okta   \n",
       "162                    0             None               McAfee   \n",
       "141                    0             None               McAfee   \n",
       "172                    0             None                 Okta   \n",
       "221                    0             None                        \n",
       "\n",
       "                     Keyword2                      Keyword3  \\\n",
       "0                                                             \n",
       "156       endpoint protection                                 \n",
       "151          network security   network security management   \n",
       "149    security vulnerability                                 \n",
       "148                                                           \n",
       "..                        ...                           ...   \n",
       "36                     McAfee                           SHI   \n",
       "162                       SHI                       NordVPN   \n",
       "141                       SHI                       NordVPN   \n",
       "172   Microsoft Authenticator                        McAfee   \n",
       "221                                                           \n",
       "\n",
       "              Keyword4             Keyword5  \\\n",
       "0                                             \n",
       "156                                           \n",
       "151   virtual firewall    security services   \n",
       "149                                           \n",
       "148                                           \n",
       "..                 ...                  ...   \n",
       "36             NordVPN                Zyxel   \n",
       "162               Okta               Ruckus   \n",
       "141               Okta               Ruckus   \n",
       "172            NordVPN   palo alto networks   \n",
       "221                                           \n",
       "\n",
       "                                               Comment  Users  \n",
       "0         1 Web Visit - 0 known contact , 1 anonymous     1.0  \n",
       "156  2 Keywords - 2 times researched by 1 anonymous...    1.0  \n",
       "151  5 Keywords - 10 times researched by 1 anonymou...    1.0  \n",
       "149  2 Keywords - 7 times researched by 1 anonymous...    1.0  \n",
       "148  1 Keyword - 1 time researched by 1 anonymous u...    1.0  \n",
       "..                                                 ...    ...  \n",
       "36   28 Keywords - 128 times researched by 65 anony...   65.0  \n",
       "162  47 Keywords - 233 times researched by 130 anon...  130.0  \n",
       "141  47 Keywords - 233 times researched by 130 anon...  130.0  \n",
       "172  68 Keywords - 514 times researched by 244 anon...  244.0  \n",
       "221                         Partner Intent Activities     NaN  \n",
       "\n",
       "[226 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Script converts 6sense emails to excel file\n",
    "# Creation date: 16 Jan 2023\n",
    "# Last modification: 29 May 2023\n",
    "# Made by: Kamil Smolag\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "\n",
    "# --Functions--\n",
    "def get_users_count(comment):\n",
    "    splits = [\" , \", \" by \"] # Possible separators in \"comment\"\n",
    "    for s in splits: # Loop to get users count \n",
    "        if s in comment:\n",
    "            users_count = comment.split(s)[1] # Taking only \" X anonymous\"\n",
    "            return int(re.search(r'\\d+', users_count).group()) # Taking only number\n",
    "        elif any(char.isdigit() for char in comment): # if digit/number in string\n",
    "            users_count = int(re.search(r'\\d+', comment).group()) # Taking only number\n",
    "        else:\n",
    "            users_count = None\n",
    "    return users_count\n",
    "\n",
    "def get_watchguard_info(company):\n",
    "    watchguard_links = () # []\n",
    "    watchguard_visitors = 0\n",
    "    try:\n",
    "        watchguards = company.find_all('span', {\"style\": \"font-size:10.0pt;color:#001F32\"})\n",
    "        for w in watchguards:\n",
    "            w = w.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\n",
    "            if \"watchguard\" in w:\n",
    "                # watchguard_links.append(w.split(\",\")[0])\n",
    "                watchguard_links += (w.split(\",\")[0],)\n",
    "                watchguard_visitors += int(re.search(r'\\d+', w.split(\",\")[1]).group())\n",
    "    except Exception as e:\n",
    "        print(\"get_watchguard_info\", e)\n",
    "        pass\n",
    "    if not watchguard_links:\n",
    "        watchguard_links = None\n",
    "    return watchguard_visitors, watchguard_links\n",
    "\n",
    "def get_email_title(sense_table):                          \n",
    "    email_titles = sense_table.find_all('span', {\"style\": re.compile(r\"^font-size:9.0pt\")}) # Taking email name\n",
    "    for title in email_titles:\n",
    "        title = title.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\n",
    "        if \"From segment:\" in title:\n",
    "            return title.split('-')[-1]\n",
    "\n",
    "def check_lists_len(date_list, activities_date_list, email_titles_list, names_list, websites_list, locations_list, buying_stage_list, profile_fit_list, account_reach_list, watchguard_visitors_list, watchguard_links_list, keyword1_list, keyword2_list, keyword3_list, keyword4_list, keyword5_list, comments_list, users_count_list):  \n",
    "    lists = [date_list, activities_date_list, email_titles_list, names_list, websites_list, locations_list, buying_stage_list, profile_fit_list, account_reach_list, watchguard_visitors_list, watchguard_links_list, keyword1_list, keyword2_list, keyword3_list, keyword4_list, keyword5_list, comments_list, users_count_list]\n",
    "    it = iter(lists)\n",
    "    the_len = len(next(it))\n",
    "    if not all(len(l) == the_len for l in it):\n",
    "        print(\"date_list\", len(date_list)) \n",
    "        print(\"activities_date_list\", len(activities_date_list)) \n",
    "        print(\"email_titles_list\", len(email_titles_list)) \n",
    "        print(\"names_list\", len(names_list))\n",
    "        print(\"websites_list\", len(websites_list)) \n",
    "        print(\"locations_list\", len(locations_list)) \n",
    "        print(\"buying_stage_list\", len(buying_stage_list)) \n",
    "        print(\"profile_fit_list\", len(profile_fit_list)) \n",
    "        print(\"account_reach_list\", len(account_reach_list))\n",
    "        print(\"watchguard_visitors_list\", len(watchguard_visitors_list))\n",
    "        print(\"watchguard_links_list\", len(watchguard_links_list))\n",
    "        print(\"keyword1_list\", len(keyword1_list))\n",
    "        print(\"keyword2_list\", len(keyword2_list))\n",
    "        print(\"keyword3_list\", len(keyword3_list)) \n",
    "        print(\"keyword4_list\", len(keyword4_list)) \n",
    "        print(\"keyword5_list\", len(keyword5_list)) \n",
    "        print(\"comments_list\", len(comments_list)) \n",
    "        print(\"users_count_list\", len(users_count_list))\n",
    "        raise ValueError('Not all lists have same length!')\n",
    "\n",
    "def scrap_email(url):\n",
    "    soup = BeautifulSoup(open(url, 'rb').read())\n",
    "    sense_table = soup.find('table', {\"style\": re.compile(r\"^max-width:565.5pt;border-collapse:collapse;mso-yfti-tbllook:1184\")}) # Fetching 6sense email table\n",
    "    company_table = sense_table.find_all('table', {\"style\": re.compile(r\"^width:100.0%;mso-cellspacing:0in;background:white;\")})\n",
    "    activities_dates = sense_table.find_all(\"p\", {\"class\": \"MsoNormal\"}) # Difficult to define correct p - checking every\n",
    "    activities_date = \"\"\n",
    "    for p in activities_dates:\n",
    "        p = p.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\n",
    "        if \"Activities\" in p: # Looking for p wich contains \"Activites from\"\n",
    "            activities_date = p.split(\": \")[1] # Taking only Date period\n",
    "            if \" - \" in activities_date:\n",
    "                activities_date = p.split(\" - \")[1] # Taking the last day\n",
    "            break\n",
    "    email_title = get_email_title(sense_table)\n",
    "    for count, company in enumerate(company_table):\n",
    "        # print(\"Company count:\", count)\n",
    "        email_titles_list.append(email_title)\n",
    "        activities_date_list.append(activities_date) # Each company has to have this\n",
    "        try:\n",
    "            name = company.find('span', {\"style\": re.compile(r\"^font-size:13.5pt\")}).text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \") # Extracting and normalizizng text\n",
    "            names_list.append(name)\n",
    "        except Exception as e:\n",
    "            print(\"'name' error:\", e)\n",
    "            print(company)\n",
    "            names_list.append(\"\")\n",
    "        # print(name)\n",
    "        website = company.find('span', {\"style\": \"color:#0082D4;text-decoration:none;text-underline:none\"})\n",
    "        website_and_location = website.find_previous(\"p\").text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \").split(\",\") #spliting \"p\" as it has 2 vars\n",
    "        website = website_and_location[0] # re-saving \"website\" to not create another variable\n",
    "        websites_list.append(website)\n",
    "        location = website_and_location[1]\n",
    "        locations_list.append(location)\n",
    "        try:\n",
    "            comment = company.find('span', {\"style\": re.compile(r\"color:#001F32\")}).text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\n",
    "            comments_list.append(comment)\n",
    "        except Exception as e:\n",
    "            print(\"'comment' error\", e)\n",
    "            comment = \"\"\n",
    "            comments_list.append(\"\")\n",
    "        users_count_list.append(get_users_count(comment))\n",
    "        watchguard_visitors_list.append(get_watchguard_info(company)[0])\n",
    "        watchguard_links_list.append(get_watchguard_info(company)[1])\n",
    "        buying_stage_count = 0\n",
    "        profile_fit_count = 0\n",
    "        account_reach_count = 0\n",
    "        for item in company.find_all('span', {\"style\": re.compile(r\"font-size:11.5pt;\")}): # Scrapping stage, fit, reach - they all have the same style \n",
    "            item = item.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\n",
    "            if \"buying stage:\" in item.lower():\n",
    "                buying_stage_list.append(item.replace(\"Buying Stage: \",\"\"))\n",
    "                buying_stage_count += 1\n",
    "            elif \"profile fit:\" in item.lower():\n",
    "                profile_fit_list.append(item.replace(\"Profile Fit: \",\"\"))\n",
    "                profile_fit_count += 1\n",
    "            elif \"account reach:\" in item.lower():\n",
    "                account_reach_list.append(item.replace(\"Account Reach: \",\"\"))\n",
    "                account_reach_count += 1\n",
    "        if buying_stage_count == 0 : buying_stage_list.append(\"\") \n",
    "        if profile_fit_count == 0 : profile_fit_list.append(\"\")\n",
    "        if account_reach_count == 0 : account_reach_list.append(\"\")\n",
    "        keywords = company.find_all('span', {\"style\": re.compile(r\"color:#505C62;\")})\n",
    "        if not keywords:\n",
    "            keyword1_list.append(\"\")\n",
    "            keyword2_list.append(\"\")\n",
    "            keyword3_list.append(\"\")\n",
    "            keyword4_list.append(\"\")\n",
    "            keyword5_list.append(\"\")\n",
    "        else:\n",
    "            for count, keyword in enumerate(keywords): # There are usually 3 keywords - loop needed\n",
    "                keyword = keyword.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \").split(\" (\")[0]\n",
    "                if len(keywords) >= 5:\n",
    "                    if count == 0:\n",
    "                        keyword1_list.append(keyword)\n",
    "                    elif count == 1:\n",
    "                        keyword2_list.append(keyword)\n",
    "                    elif count == 2:\n",
    "                        keyword3_list.append(keyword)\n",
    "                    elif count == 3:\n",
    "                        keyword4_list.append(keyword)\n",
    "                    elif count == 4:\n",
    "                        keyword5_list.append(keyword)\n",
    "                if len(keywords) == 4:\n",
    "                    if count == 0:\n",
    "                        keyword1_list.append(keyword)\n",
    "                    elif count == 1:\n",
    "                        keyword2_list.append(keyword)\n",
    "                    elif count == 2:\n",
    "                        keyword3_list.append(keyword)\n",
    "                    elif count == 3:\n",
    "                        keyword4_list.append(keyword)\n",
    "                        keyword5_list.append(\"\")\n",
    "                if len(keywords) == 3:\n",
    "                    if count == 0:\n",
    "                        keyword1_list.append(keyword)\n",
    "                    elif count == 1:\n",
    "                        keyword2_list.append(keyword)\n",
    "                    elif count == 2:\n",
    "                        keyword3_list.append(keyword)\n",
    "                        keyword4_list.append(\"\")\n",
    "                        keyword5_list.append(\"\")\n",
    "                elif len(keywords) == 2: \n",
    "                    if count == 0:\n",
    "                        keyword1_list.append(keyword)\n",
    "                    elif count == 1:\n",
    "                        keyword2_list.append(keyword)\n",
    "                        keyword3_list.append(\"\")\n",
    "                        keyword4_list.append(\"\")\n",
    "                        keyword5_list.append(\"\")\n",
    "                elif len(keywords) == 1:\n",
    "                    keyword1_list.append(keyword)\n",
    "                    keyword2_list.append(\"\")\n",
    "                    keyword3_list.append(\"\")\n",
    "                    keyword4_list.append(\"\")\n",
    "                    keyword5_list.append(\"\")\n",
    "\n",
    "# --Vars--\n",
    "date_list = []\n",
    "activities_date_list = []\n",
    "names_list = []\n",
    "websites_list = []\n",
    "locations_list = []\n",
    "buying_stage_list = []\n",
    "profile_fit_list = []\n",
    "account_reach_list = []\n",
    "keyword1_list = []\n",
    "keyword2_list = []\n",
    "keyword3_list = []\n",
    "keyword4_list = []\n",
    "keyword5_list = []\n",
    "comments_list = []\n",
    "users_count_list = []\n",
    "watchguard_visitors_list = []\n",
    "watchguard_links_list = []\n",
    "email_titles_list = []\n",
    "\n",
    "\n",
    "# --Main-code--\n",
    "if __name__ == \"__main__\":\n",
    "    path = os.getcwd()\n",
    "    html_files = glob.glob(os.path.join(path, \"*.html\"))\n",
    "    html_files += glob.glob(os.path.join(path, \"*.htm\"))\n",
    "    print(\"Found\", len(html_files), \"HTML files\")\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for count, url in enumerate(html_files):\n",
    "        print(\"URL count:\", count)\n",
    "        print(url)\n",
    "        scrap_email(url)\n",
    "\n",
    "    for name in names_list:\n",
    "        date_list.append(dt.datetime.today().strftime(\"%d-%b-%Y\"))\n",
    "\n",
    "    check_lists_len(date_list, activities_date_list, email_titles_list, names_list, websites_list, locations_list, buying_stage_list, profile_fit_list, account_reach_list, watchguard_visitors_list, watchguard_links_list, keyword1_list, keyword2_list, keyword3_list, keyword4_list, keyword5_list, comments_list, users_count_list)\n",
    "\n",
    "    dict = {\n",
    "        \"Date added\": date_list,\n",
    "        \"Activity date\": activities_date_list,\n",
    "        \"Email title\": email_titles_list,\n",
    "        \"Name\": names_list,\n",
    "        \"Website\": websites_list,\n",
    "        \"Location\": locations_list,\n",
    "        \"Buying stage\": buying_stage_list,\n",
    "        \"Profile fit\": profile_fit_list,\n",
    "        \"Account reach\": account_reach_list,\n",
    "        \"Watchguard visitors\": watchguard_visitors_list,\n",
    "        \"Watchguard links\": tuple(watchguard_links_list),\n",
    "        \"Keyword1\": keyword1_list,\n",
    "        \"Keyword2\": keyword2_list,\n",
    "        \"Keyword3\": keyword3_list,\n",
    "        \"Keyword4\": keyword4_list,\n",
    "        \"Keyword5\": keyword5_list,\n",
    "        \"Comment\": comments_list,\n",
    "        \"Users\": users_count_list,\n",
    "    }\n",
    "\n",
    "    df_data = pd.DataFrame(dict).sort_values(by=\"Users\")\n",
    "    # print(df_data)\n",
    "    searchfor = [\"school\", \"schools\", \"education\"] # Filter DataFrame \n",
    "    df_data_schools = df_data[df_data[\"Name\"].str.contains('|'.join(searchfor), na=False, case=False)].drop_duplicates(keep='first') # Separeting schools from rest\n",
    "    df_data_manufacturers = df_data[df_data[\"Email title\"].str.contains(\"Manufacturers\", na=False, case=False)].drop_duplicates(keep='first') # Separeting manufacturers from rest\n",
    "    df_data_legal = df_data[df_data[\"Email title\"].str.contains(\"Legal\", na=False, case=False)].drop_duplicates(keep='first') # Separeting manufacturers from rest\n",
    "    df_data = pd.concat([df_data, df_data_schools, df_data_manufacturers, df_data_legal]).drop_duplicates(keep='first')\n",
    "    df_keywords1 = df_data.filter(['Activity date', 'Keyword1'], axis=1).rename(columns = {'Keyword1':'Keywords' }) # Creating new DF and renaming Keyword1 column\n",
    "    df_keywords2 = df_data.filter(['Activity date', 'Keyword2'], axis=1).rename(columns = {'Keyword2':'Keywords' })\n",
    "    df_keywords3 = df_data.filter(['Activity date', 'Keyword3'], axis=1).rename(columns = {'Keyword3':'Keywords' })\n",
    "    df_keywords4 = df_data.filter(['Activity date', 'Keyword4'], axis=1).rename(columns = {'Keyword4':'Keywords' })\n",
    "    df_keywords5 = df_data.filter(['Activity date', 'Keyword5'], axis=1).rename(columns = {'Keyword5':'Keywords' })\n",
    "    df_keywords = pd.concat([df_keywords1, df_keywords2, df_keywords3, df_keywords4, df_keywords5]) # Merging all keywordsX into want DF\n",
    "    df_keywords = df_keywords[df_keywords[\"Keywords\"].astype(bool)].sort_values(\"Activity date\", ascending=False) # Droping empty cells in \"Keywords\" and sorting\n",
    "    pivot_keywords = pd.pivot_table(df_keywords, index=\"Keywords\", aggfunc='count').rename(columns = {'Activity date':'count' }).sort_values(by=\"count\", ascending=False)\n",
    "    current_date = dt.datetime.now().strftime(\"%d-%b-%Y\")\n",
    "    # Creating folder with current date\n",
    "    folder_path = path + r\"\\_master_files\\\\\" + current_date\n",
    "    print(folder_path)\n",
    "    if not os.path.exists(folder_path) : os.makedirs(folder_path) \n",
    "    # Saving everything to master_file excel\n",
    "    with pd.ExcelWriter(folder_path + f\"/6sense_master_file_{current_date}.xlsx\") as writer:  # Saving data to file \n",
    "        df_data.to_excel(writer, sheet_name=\"Data\", index=False)\n",
    "        df_data_schools.to_excel(writer, sheet_name=\"Data_schools\", index=False)\n",
    "        df_data_manufacturers.to_excel(writer, sheet_name=\"Data_manufacturers\", index=False)\n",
    "        df_data_legal.to_excel(writer, sheet_name=\"Data_legal\", index=False)\n",
    "        pivot_keywords.to_excel(writer, sheet_name=\"Keywords_pivot\")\n",
    "        df_keywords.to_excel(writer, sheet_name=\"Keywords\", index=False)\n",
    "        print(f\"File 6sense_master_file_{current_date}.xlsx saved in {folder_path}\")\n",
    "    #Saving only websites of given type to excel files (for UpLead)\n",
    "    manufacturers_only_websites = df_data_manufacturers[['Website']].drop_duplicates(keep='first')\n",
    "    manufacturers_only_websites.to_csv(folder_path + f\"\\websites_only_Manufacturers_{current_date}.csv\", index=False)\n",
    "    legal_only_websites = df_data_legal[['Website']].drop_duplicates(keep='first')\n",
    "    legal_only_websites.to_csv(folder_path + f\"\\websites_only_Legal_{current_date}.csv\", index=False)\n",
    "df_data\n",
    "\n",
    "# To do:\n",
    "# create DataBase graph for files/make logic (https://drawsql.app/teams/mesyv/diagrams/6sense-data)\n",
    "# Take email list from hunter and uplead for: Manufacturers and Legal \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8065859a666a0a35ff186cc2b2b1d9fd6755a5e815cd2155f24ca932ca25e802"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
