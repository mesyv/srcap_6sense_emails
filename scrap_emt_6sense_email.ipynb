{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Script converts 6sense emails to excel file\r\n",
    "# Creation date: 16 Jan 2023\r\n",
    "# Last modification: 29 March 2023\r\n",
    "# Made by: Kamil Smolag\r\n",
    "\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import os\r\n",
    "import glob\r\n",
    "import datetime as dt\r\n",
    "\r\n",
    "# --Functions--\r\n",
    "def get_users_count(comment):\r\n",
    "    splits = [\" , \", \" by \"] # Possible separators in \"comment\"\r\n",
    "    for s in splits: # Loop to get users count \r\n",
    "        if s in comment:\r\n",
    "            users_count = comment.split(s)[1] # Taking only \" X anonymous\"\r\n",
    "            return int(re.search(r'\\d+', users_count).group()) # Taking only number\r\n",
    "        elif any(char.isdigit() for char in comment): # if digit/number in string\r\n",
    "            users_count = int(re.search(r'\\d+', comment).group()) # Taking only number\r\n",
    "        else:\r\n",
    "            users_count = None\r\n",
    "    return users_count\r\n",
    "\r\n",
    "def get_watchguard_info(company):\r\n",
    "    watchguard_links = () # []\r\n",
    "    watchguard_visitors = 0\r\n",
    "    try:\r\n",
    "        watchguards = company.find_all('span', {\"style\": \"font-size:10.0pt;color:#001F32\"})\r\n",
    "        for w in watchguards:\r\n",
    "            w = w.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "            if \"watchguard\" in w:\r\n",
    "                # watchguard_links.append(w.split(\",\")[0])\r\n",
    "                watchguard_links += (w.split(\",\")[0],)\r\n",
    "                watchguard_visitors += int(re.search(r'\\d+', w.split(\",\")[1]).group())\r\n",
    "    except Exception as e:\r\n",
    "        print(\"get_watchguard_info\", e)\r\n",
    "        pass\r\n",
    "    if not watchguard_links:\r\n",
    "        watchguard_links = None\r\n",
    "    return watchguard_visitors, watchguard_links\r\n",
    "\r\n",
    "def get_email_title(sense_table):                          \r\n",
    "    email_titles = sense_table.find_all('span', {\"style\": re.compile(r\"^font-size:9.0pt\")}) # Taking email name\r\n",
    "    for title in email_titles:\r\n",
    "        title = title.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "        if \"From segment:\" in title:\r\n",
    "            return title.split('-')[-1]\r\n",
    "\r\n",
    "def check_lists_len(date_list, activities_date_list, email_titles_list, names_list, websites_list, locations_list, buying_stage_list, profile_fit_list, account_reach_list, watchguard_visitors_list, watchguard_links_list, keyword1_list, keyword2_list, keyword3_list, keyword4_list, keyword5_list, comments_list, users_count_list):  \r\n",
    "    lists = [date_list, activities_date_list, email_titles_list, names_list, websites_list, locations_list, buying_stage_list, profile_fit_list, account_reach_list, watchguard_visitors_list, watchguard_links_list, keyword1_list, keyword2_list, keyword3_list, keyword4_list, keyword5_list, comments_list, users_count_list]\r\n",
    "    it = iter(lists)\r\n",
    "    the_len = len(next(it))\r\n",
    "    if not all(len(l) == the_len for l in it):\r\n",
    "        print(\"date_list\", len(date_list)) \r\n",
    "        print(\"activities_date_list\", len(activities_date_list)) \r\n",
    "        print(\"email_titles_list\", len(email_titles_list)) \r\n",
    "        print(\"names_list\", len(names_list))\r\n",
    "        print(\"websites_list\", len(websites_list)) \r\n",
    "        print(\"locations_list\", len(locations_list)) \r\n",
    "        print(\"buying_stage_list\", len(buying_stage_list)) \r\n",
    "        print(\"profile_fit_list\", len(profile_fit_list)) \r\n",
    "        print(\"account_reach_list\", len(account_reach_list))\r\n",
    "        print(\"watchguard_visitors_list\", len(watchguard_visitors_list))\r\n",
    "        print(\"watchguard_links_list\", len(watchguard_links_list))\r\n",
    "        print(\"keyword1_list\", len(keyword1_list))\r\n",
    "        print(\"keyword2_list\", len(keyword2_list))\r\n",
    "        print(\"keyword3_list\", len(keyword3_list)) \r\n",
    "        print(\"keyword4_list\", len(keyword4_list)) \r\n",
    "        print(\"keyword5_list\", len(keyword5_list)) \r\n",
    "        print(\"comments_list\", len(comments_list)) \r\n",
    "        print(\"users_count_list\", len(users_count_list))\r\n",
    "        raise ValueError('Not all lists have same length!')\r\n",
    "\r\n",
    "def scrap_email(url):\r\n",
    "    soup = BeautifulSoup(open(url, 'rb').read())\r\n",
    "    sense_table = soup.find('table', {\"style\": re.compile(r\"^max-width:565.5pt;border-collapse:collapse;mso-yfti-tbllook:1184\")}) # Fetching 6sense email table\r\n",
    "    company_table = sense_table.find_all('table', {\"style\": re.compile(r\"^width:100.0%;mso-cellspacing:0in;background:white;\")})\r\n",
    "    activities_dates = sense_table.find_all(\"p\", {\"class\": \"MsoNormal\"}) # Difficult to define correct p - checking every\r\n",
    "    activities_date = \"\"\r\n",
    "    for p in activities_dates:\r\n",
    "        p = p.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "        if \"Activities\" in p: # Looking for p wich contains \"Activites from\"\r\n",
    "            activities_date = p.split(\": \")[1] # Taking only Date period\r\n",
    "            if \" - \" in activities_date:\r\n",
    "                activities_date = p.split(\" - \")[1] # Taking the last day\r\n",
    "            break\r\n",
    "    email_title = get_email_title(sense_table)\r\n",
    "    for count, company in enumerate(company_table):\r\n",
    "        # print(\"Company count:\", count)\r\n",
    "        email_titles_list.append(email_title)\r\n",
    "        activities_date_list.append(activities_date) # Each company has to have this\r\n",
    "        try:\r\n",
    "            name = company.find('span', {\"style\": re.compile(r\"^font-size:13.5pt\")}).text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \") # Extracting and normalizizng text\r\n",
    "            names_list.append(name)\r\n",
    "        except Exception as e:\r\n",
    "            print(\"'name' error:\", e)\r\n",
    "            print(company)\r\n",
    "            names_list.append(\"\")\r\n",
    "        # print(name)\r\n",
    "        website = company.find('span', {\"style\": \"color:#0082D4;text-decoration:none;text-underline:none\"})\r\n",
    "        website_and_location = website.find_previous(\"p\").text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \").split(\",\") #spliting \"p\" as it has 2 vars\r\n",
    "        website = website_and_location[0] # re-saving \"website\" to not create another variable\r\n",
    "        websites_list.append(website)\r\n",
    "        location = website_and_location[1]\r\n",
    "        locations_list.append(location)\r\n",
    "        try:\r\n",
    "            comment = company.find('span', {\"style\": re.compile(r\"color:#001F32\")}).text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "            comments_list.append(comment)\r\n",
    "        except Exception as e:\r\n",
    "            print(\"'comment' error\", e)\r\n",
    "            # comment = \"\"\r\n",
    "            comments_list.append(\"\")\r\n",
    "        users_count_list.append(get_users_count(comment))\r\n",
    "        watchguard_visitors_list.append(get_watchguard_info(company)[0])\r\n",
    "        watchguard_links_list.append(get_watchguard_info(company)[1])\r\n",
    "        for item in company.find_all('span', {\"style\": re.compile(r\"font-size:11.5pt;\")}): # Scrapping stage, fit, reach - they all have the same style \r\n",
    "            item = item.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "            if \"buying stage:\" in item.lower():\r\n",
    "                buying_stage_list.append(item.replace(\"Buying Stage: \",\"\"))\r\n",
    "            elif \"profile fit:\" in item.lower():\r\n",
    "                profile_fit_list.append(item.replace(\"Profile Fit: \",\"\"))\r\n",
    "            elif \"account reach:\" in item.lower():\r\n",
    "                account_reach_list.append(item.replace(\"Account Reach: \",\"\"))\r\n",
    "        keywords = company.find_all('span', {\"style\": re.compile(r\"color:#505C62;\")})\r\n",
    "        if not keywords:\r\n",
    "            keyword1_list.append(\"\")\r\n",
    "            keyword2_list.append(\"\")\r\n",
    "            keyword3_list.append(\"\")\r\n",
    "            keyword4_list.append(\"\")\r\n",
    "            keyword5_list.append(\"\")\r\n",
    "        else:\r\n",
    "            for count, keyword in enumerate(keywords): # There are usually 3 keywords - loop needed\r\n",
    "                keyword = keyword.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \").split(\" (\")[0]\r\n",
    "                if len(keywords) >= 5:\r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                    elif count == 2:\r\n",
    "                        keyword3_list.append(keyword)\r\n",
    "                    elif count == 3:\r\n",
    "                        keyword4_list.append(keyword)\r\n",
    "                    elif count == 4:\r\n",
    "                        keyword5_list.append(keyword)\r\n",
    "                if len(keywords) == 4:\r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                    elif count == 2:\r\n",
    "                        keyword3_list.append(keyword)\r\n",
    "                    elif count == 3:\r\n",
    "                        keyword4_list.append(keyword)\r\n",
    "                        keyword5_list.append(\"\")\r\n",
    "                if len(keywords) == 3:\r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                    elif count == 2:\r\n",
    "                        keyword3_list.append(keyword)\r\n",
    "                        keyword4_list.append(\"\")\r\n",
    "                        keyword5_list.append(\"\")\r\n",
    "                elif len(keywords) == 2: \r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                        keyword3_list.append(\"\")\r\n",
    "                        keyword4_list.append(\"\")\r\n",
    "                        keyword5_list.append(\"\")\r\n",
    "                elif len(keywords) == 1:\r\n",
    "                    keyword1_list.append(keyword)\r\n",
    "                    keyword2_list.append(\"\")\r\n",
    "                    keyword3_list.append(\"\")\r\n",
    "                    keyword4_list.append(\"\")\r\n",
    "                    keyword5_list.append(\"\")\r\n",
    "\r\n",
    "# --Vars--\r\n",
    "date_list = []\r\n",
    "activities_date_list = []\r\n",
    "names_list = []\r\n",
    "websites_list = []\r\n",
    "locations_list = []\r\n",
    "buying_stage_list = []\r\n",
    "profile_fit_list = []\r\n",
    "account_reach_list = []\r\n",
    "keyword1_list = []\r\n",
    "keyword2_list = []\r\n",
    "keyword3_list = []\r\n",
    "keyword4_list = []\r\n",
    "keyword5_list = []\r\n",
    "comments_list = []\r\n",
    "users_count_list = []\r\n",
    "watchguard_visitors_list = []\r\n",
    "watchguard_links_list = []\r\n",
    "email_titles_list = []\r\n",
    "\r\n",
    "\r\n",
    "# --Main-code--\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    path = os.getcwd()\r\n",
    "    html_files = glob.glob(os.path.join(path, \"*.html\"))\r\n",
    "    html_files += glob.glob(os.path.join(path, \"*.htm\"))\r\n",
    "    print(\"Found\", len(html_files), \"HTML files\")\r\n",
    "\r\n",
    "    i = 0\r\n",
    "\r\n",
    "    for count, url in enumerate(html_files):\r\n",
    "        # print(\"URL count:\", count)\r\n",
    "        # print(url)\r\n",
    "        scrap_email(url)\r\n",
    "\r\n",
    "    for name in names_list:\r\n",
    "        date_list.append(dt.datetime.today().strftime(\"%d-%b-%Y\"))\r\n",
    "\r\n",
    "    check_lists_len(date_list, activities_date_list, email_titles_list, names_list, websites_list, locations_list, buying_stage_list, profile_fit_list, account_reach_list, watchguard_visitors_list, watchguard_links_list, keyword1_list, keyword2_list, keyword3_list, keyword4_list, keyword5_list, comments_list, users_count_list)\r\n",
    "\r\n",
    "    dict = {\r\n",
    "        \"Date added\": date_list,\r\n",
    "        \"Activity date\": activities_date_list,\r\n",
    "        \"Email title\": email_titles_list,\r\n",
    "        \"Name\": names_list,\r\n",
    "        \"Website\": websites_list,\r\n",
    "        \"Location\": locations_list,\r\n",
    "        \"Buying stage\": buying_stage_list,\r\n",
    "        \"Profile fit\": profile_fit_list,\r\n",
    "        \"Account reach\": account_reach_list,\r\n",
    "        \"Watchguard visitors\": watchguard_visitors_list,\r\n",
    "        \"Watchguard links\": tuple(watchguard_links_list),\r\n",
    "        \"Keyword1\": keyword1_list,\r\n",
    "        \"Keyword2\": keyword2_list,\r\n",
    "        \"Keyword3\": keyword3_list,\r\n",
    "        \"Keyword4\": keyword4_list,\r\n",
    "        \"Keyword5\": keyword5_list,\r\n",
    "        \"Comment\": comments_list,\r\n",
    "        \"Users\": users_count_list,\r\n",
    "    }\r\n",
    "\r\n",
    "    df_data = pd.DataFrame(dict).sort_values(by=\"Users\")\r\n",
    "    searchfor = [\"school\", \"schools\", \"education\"] # Filter DataFrame \r\n",
    "    df_data_schools = df_data[df_data[\"Name\"].str.contains('|'.join(searchfor), na=False, case=False)].drop_duplicates(keep=False) # Separeting schools from rest\r\n",
    "    df_data_manufacturers = df_data[df_data[\"Email title\"].str.contains(\"Manufacturers\", na=False, case=False)].drop_duplicates(keep=False) # Separeting manufacturers from rest\r\n",
    "    df_data_legal = df_data[df_data[\"Email title\"].str.contains(\"Legal\", na=False, case=False)].drop_duplicates(keep=False) # Separeting manufacturers from rest\r\n",
    "    df_data = pd.concat([df_data, df_data_schools, df_data_manufacturers, df_data_legal]).drop_duplicates(keep=False)\r\n",
    "    df_keywords1 = df_data.filter(['Activity date', 'Keyword1'], axis=1).rename(columns = {'Keyword1':'Keywords' }) # Creating new DF and renaming Keyword1 column\r\n",
    "    df_keywords2 = df_data.filter(['Activity date', 'Keyword2'], axis=1).rename(columns = {'Keyword2':'Keywords' })\r\n",
    "    df_keywords3 = df_data.filter(['Activity date', 'Keyword3'], axis=1).rename(columns = {'Keyword3':'Keywords' })\r\n",
    "    df_keywords4 = df_data.filter(['Activity date', 'Keyword4'], axis=1).rename(columns = {'Keyword4':'Keywords' })\r\n",
    "    df_keywords5 = df_data.filter(['Activity date', 'Keyword5'], axis=1).rename(columns = {'Keyword5':'Keywords' })\r\n",
    "    df_keywords = pd.concat([df_keywords1, df_keywords2, df_keywords3, df_keywords4, df_keywords5]) # Merging all keywordsX into want DF\r\n",
    "    df_keywords = df_keywords[df_keywords[\"Keywords\"].astype(bool)].sort_values(\"Activity date\", ascending=False) # Droping empty cells in \"Keywords\" and sorting\r\n",
    "    # pivot_keywords = pd.pivot_table(df_keywords, index=\"Keywords\", aggfunc='count').rename(columns = {'Activity date':'count' }).sort_values(by=\"count\", ascending=False)\r\n",
    "    current_date = dt.datetime.now().strftime(\"%d-%b-%Y\")\r\n",
    "\r\n",
    "    with pd.ExcelWriter(path + f\"/6sense_master_file_{current_date}.xlsx\") as writer:  # Saving data to file \r\n",
    "        df_data.to_excel(writer, sheet_name=\"Data\", index=False)\r\n",
    "        df_data_schools.to_excel(writer, sheet_name=\"Data_schools\", index=False)\r\n",
    "        df_data_manufacturers.to_excel(writer, sheet_name=\"Data_manufacturers\", index=False)\r\n",
    "        df_data_legal.to_excel(writer, sheet_name=\"Data_legal\", index=False)\r\n",
    "        # pivot_keywords.to_excel(writer, sheet_name=\"Keywords_pivot\")\r\n",
    "        df_keywords.to_excel(writer, sheet_name=\"Keywords\", index=False)\r\n",
    "        print(f\"File 6sense_master_file_{current_date}.xlsx saved\")\r\n",
    "df_data\r\n",
    "\r\n",
    "# To do:\r\n",
    "# create DataBase graph for files/make logic (https://drawsql.app/teams/mesyv/diagrams/6sense-data)\r\n",
    "# Take email list from hunter and uplead for: Manufacturers and Legal \r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 47 HTML files\n",
      "File 6sense_master_file_16-May-2023.xlsx saved\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Date added Activity date                     Email title  \\\n",
       "251  16-May-2023                 ARMA NYC List 1  August 2021    \n",
       "250  16-May-2023                 ARMA NYC List 1  August 2021    \n",
       "248  16-May-2023                 ARMA NYC List 1  August 2021    \n",
       "247  16-May-2023                 ARMA NYC List 1  August 2021    \n",
       "442  16-May-2023                       NE eMazzanti IACC List    \n",
       "..           ...           ...                             ...   \n",
       "307  16-May-2023                  NE eMazzanti ARMA NYC List3    \n",
       "438  16-May-2023                       NE eMazzanti IACC List    \n",
       "439  16-May-2023                       NE eMazzanti IACC List    \n",
       "446  16-May-2023                       NE eMazzanti IACC List    \n",
       "449  16-May-2023                       NE eMazzanti IACC List    \n",
       "\n",
       "                                                  Name               Website  \\\n",
       "251                                    Northern Water      northernwater.org   \n",
       "250                              City Of Pflugerville     pflugervilletx.gov   \n",
       "248             North Carolina Housing Finance Agency              nchfa.com   \n",
       "247                              The Frick Collection              frick.org   \n",
       "442                              Pavia & Harcourt LLP           pavialaw.com   \n",
       "..                                                 ...                   ...   \n",
       "307                Golden Spread Electric Cooperative              gsec.coop   \n",
       "438  Borah, Goldstein, Altschuler, Nahins & Goidel,...    borahgoldstein.com   \n",
       "439                                       Level Group         levelgroup.com   \n",
       "446                                       Level Group         levelgroup.com   \n",
       "449                          Frederick Wildman & Sons   frederickwildman.com   \n",
       "\n",
       "            Location    Buying stage Profile fit Account reach  \\\n",
       "251   United States   Consideration      Strong           Low    \n",
       "250   United States   Consideration      Strong           Low    \n",
       "248   United States       Awareness    Moderate           Low    \n",
       "247   United States       Awareness      Strong           Low    \n",
       "442   United States          Target      Strong           Low    \n",
       "..               ...             ...         ...           ...   \n",
       "307   United States       Awareness    Moderate           Low    \n",
       "438   United States   Consideration      Strong           Low    \n",
       "439   United States       Awareness      Strong           Low    \n",
       "446   United States   Consideration      Strong           Low    \n",
       "449   United States       Awareness      Strong           Low    \n",
       "\n",
       "     Watchguard visitors Watchguard links                      Keyword1  \\\n",
       "251                    0             None       Virtual Private Network   \n",
       "250                    0             None                           utm   \n",
       "248                    0             None              network security   \n",
       "247                    0             None                        McAfee   \n",
       "442                    0             None   multi factor authentication   \n",
       "..                   ...              ...                           ...   \n",
       "307                    0             None                                 \n",
       "438                    0             None                                 \n",
       "439                    0             None                                 \n",
       "446                    0             None                                 \n",
       "449                    0             None                                 \n",
       "\n",
       "    Keyword2 Keyword3 Keyword4 Keyword5  \\\n",
       "251                                       \n",
       "250                                       \n",
       "248      mfa                              \n",
       "247                                       \n",
       "442                                       \n",
       "..       ...      ...      ...      ...   \n",
       "307                                       \n",
       "438                                       \n",
       "439                                       \n",
       "446                                       \n",
       "449                                       \n",
       "\n",
       "                                               Comment  Users  \n",
       "251  1 Keyword - 1 time researched by 1 anonymous u...    1.0  \n",
       "250  1 Keyword - 1 time researched by 1 anonymous u...    1.0  \n",
       "248  2 Keywords - 3 times researched by 1 anonymous...    1.0  \n",
       "247  1 Keyword - 1 time researched by 1 anonymous u...    1.0  \n",
       "442  1 Keyword - 2 times researched by 1 anonymous ...    1.0  \n",
       "..                                                 ...    ...  \n",
       "307                         Partner Intent Activities     NaN  \n",
       "438                         Partner Intent Activities     NaN  \n",
       "439                         Partner Intent Activities     NaN  \n",
       "446                         Partner Intent Activities     NaN  \n",
       "449                         Partner Intent Activities     NaN  \n",
       "\n",
       "[246 rows x 18 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date added</th>\n",
       "      <th>Activity date</th>\n",
       "      <th>Email title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Website</th>\n",
       "      <th>Location</th>\n",
       "      <th>Buying stage</th>\n",
       "      <th>Profile fit</th>\n",
       "      <th>Account reach</th>\n",
       "      <th>Watchguard visitors</th>\n",
       "      <th>Watchguard links</th>\n",
       "      <th>Keyword1</th>\n",
       "      <th>Keyword2</th>\n",
       "      <th>Keyword3</th>\n",
       "      <th>Keyword4</th>\n",
       "      <th>Keyword5</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>Northern Water</td>\n",
       "      <td>northernwater.org</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Virtual Private Network</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 Keyword - 1 time researched by 1 anonymous u...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>City Of Pflugerville</td>\n",
       "      <td>pflugervilletx.gov</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>utm</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 Keyword - 1 time researched by 1 anonymous u...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>North Carolina Housing Finance Agency</td>\n",
       "      <td>nchfa.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>network security</td>\n",
       "      <td>mfa</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2 Keywords - 3 times researched by 1 anonymous...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>ARMA NYC List 1  August 2021</td>\n",
       "      <td>The Frick Collection</td>\n",
       "      <td>frick.org</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>McAfee</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 Keyword - 1 time researched by 1 anonymous u...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>NE eMazzanti IACC List</td>\n",
       "      <td>Pavia &amp; Harcourt LLP</td>\n",
       "      <td>pavialaw.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Target</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>multi factor authentication</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1 Keyword - 2 times researched by 1 anonymous ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>NE eMazzanti ARMA NYC List3</td>\n",
       "      <td>Golden Spread Electric Cooperative</td>\n",
       "      <td>gsec.coop</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partner Intent Activities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>NE eMazzanti IACC List</td>\n",
       "      <td>Borah, Goldstein, Altschuler, Nahins &amp; Goidel,...</td>\n",
       "      <td>borahgoldstein.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partner Intent Activities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>NE eMazzanti IACC List</td>\n",
       "      <td>Level Group</td>\n",
       "      <td>levelgroup.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partner Intent Activities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>NE eMazzanti IACC List</td>\n",
       "      <td>Level Group</td>\n",
       "      <td>levelgroup.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Consideration</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partner Intent Activities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>16-May-2023</td>\n",
       "      <td></td>\n",
       "      <td>NE eMazzanti IACC List</td>\n",
       "      <td>Frederick Wildman &amp; Sons</td>\n",
       "      <td>frederickwildman.com</td>\n",
       "      <td>United States</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partner Intent Activities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 18 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "current_date = dt.datetime.now().strftime(\"%Y-%b-%d\")\r\n",
    "print(current_date)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2023-May-16\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.13 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "8065859a666a0a35ff186cc2b2b1d9fd6755a5e815cd2155f24ca932ca25e802"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}