{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Script converts 6sense emails to excel file\r\n",
    "# Creation date: 16 Jan 2023\r\n",
    "# Last modification: 17 Feb 2023\r\n",
    "# Made by: Kamil Smolag\r\n",
    "\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "import os\r\n",
    "import glob\r\n",
    "import datetime as dt\r\n",
    "\r\n",
    "# --Functions--\r\n",
    "def get_users_count(comment):\r\n",
    "    splits = [\" , \", \" by \"] # Possible separators in \"comment\"\r\n",
    "    for s in splits: # Loop to get users count \r\n",
    "        if s in comment:\r\n",
    "            users_count = comment.split(s)[1] # Taking only \" X anonymous\"\r\n",
    "            return int(re.search(r'\\d+', users_count).group()) # Taking only number\r\n",
    "        elif any(char.isdigit() for char in comment): # if digit/number in string\r\n",
    "            users_count = int(re.search(r'\\d+', comment).group()) # Taking only number\r\n",
    "        else:\r\n",
    "            users_count = None\r\n",
    "    return users_count\r\n",
    "\r\n",
    "def get_watchguard_info(company):\r\n",
    "    watchguard_links = []\r\n",
    "    watchguard_visitors = 0\r\n",
    "    try:\r\n",
    "        watchguards = company.find_all('span', {\"style\": \"font-size:10.0pt;color:#001F32\"})\r\n",
    "        for w in watchguards:\r\n",
    "            w = w.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "            if \"watchguard\" in w:\r\n",
    "                watchguard_links.append(w.split(\",\")[0])\r\n",
    "                watchguard_visitors += int(re.search(r'\\d+', w.split(\",\")[1]).group())\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "        pass\r\n",
    "    return watchguard_visitors, watchguard_links\r\n",
    "\r\n",
    "def scrap_email(url):\r\n",
    "    soup = BeautifulSoup(open(url, 'rb').read())\r\n",
    "    sense_table = soup.find('table', {\"style\": re.compile(r\"^max-width:565.5pt;border-collapse:collapse;mso-yfti-tbllook:1184\")}) # Fetching 6sense email table\r\n",
    "    company_table = sense_table.find_all('table', {\"style\": re.compile(r\"^width:100.0%;mso-cellspacing:0in;background:white;\")})\r\n",
    "    activities_dates = sense_table.find_all(\"p\", {\"class\": \"MsoNormal\"}) # Difficult to define correct p - checking every\r\n",
    "    activities_date = \"\"\r\n",
    "    for p in activities_dates:\r\n",
    "        if \"Activities from\" in p.text: # Looking for p wich contains \"Activites from\"\r\n",
    "            activities_date = p.text.split(\"Activities from : \")[1] # Taking only Date period\r\n",
    "            if \" - \" in activities_date:\r\n",
    "                activities_date = p.text.split(\" - \")[1] # Taking the last day\r\n",
    "            break\r\n",
    "        elif \"Activities on : \" in p.text:\r\n",
    "            activities_date = p.text.split(\"Activities on : \")[1]\r\n",
    "            break\r\n",
    "    for company in company_table:\r\n",
    "        activities_date_list.append(activities_date) # Each company has to have this\r\n",
    "        name = company.find('span', {\"style\": \"font-size:13.5pt\"}).text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \") # Extracting and normalizizng text\r\n",
    "        names_list.append(name)\r\n",
    "        website = company.find('span', {\"style\": \"color:#0082D4;text-decoration:none;text-underline:none\"})\r\n",
    "        website_and_location = website.find_previous(\"p\").text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \").split(\",\") #spliting \"p\" as it has 2 vars\r\n",
    "        website = website_and_location[0] # re-saving \"website\" to not create another variable\r\n",
    "        websites_list.append(website)\r\n",
    "        location = website_and_location[1]\r\n",
    "        locations_list.append(location)\r\n",
    "        comment = company.find('span', {\"style\": \"font-size:11.5pt;color:#001F32\"}).text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "        comments_list.append(comment)\r\n",
    "        users_count_list.append(get_users_count(comment))\r\n",
    "        watchguard_visitors_list.append(get_watchguard_info(company)[0])\r\n",
    "        watchguard_links_list.append(get_watchguard_info(company)[1])\r\n",
    "        for item in company.find_all('span', {\"style\": \"font-size:11.5pt;color:black\"}): # Scrapping stage, fit, reach - they all have the same style \r\n",
    "            item = item.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \")\r\n",
    "            if \"buying stage:\" in item.lower():\r\n",
    "                buying_stage_list.append(item.replace(\"Buying Stage: \",\"\"))\r\n",
    "            elif \"profile fit:\" in item.lower():\r\n",
    "                profile_fit_list.append(item.replace(\"Profile Fit: \",\"\"))\r\n",
    "            elif \"account reach:\" in item.lower():\r\n",
    "                account_reach_list.append(item.replace(\"Account Reach: \",\"\"))\r\n",
    "        keywords = company.find_all('span', {\"style\": re.compile(r\"^font-size:10.5pt;color:#505C62;\")})\r\n",
    "        if not keywords:\r\n",
    "            keyword1_list.append(\"\")\r\n",
    "            keyword2_list.append(\"\")\r\n",
    "            keyword3_list.append(\"\")\r\n",
    "            keyword4_list.append(\"\")\r\n",
    "            keyword5_list.append(\"\")\r\n",
    "        else:\r\n",
    "            for count, keyword in enumerate(keywords): # There are usually 3 keywords - loop needed\r\n",
    "                keyword = keyword.text.replace(\"\\r\",\"\").replace(\"  \",\"\").replace(\"\\n\",\" \").split(\" (\")[0]\r\n",
    "                if len(keywords) >= 5:\r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                    elif count == 2:\r\n",
    "                        keyword3_list.append(keyword)\r\n",
    "                    elif count == 3:\r\n",
    "                        keyword4_list.append(keyword)\r\n",
    "                    elif count == 4:\r\n",
    "                        keyword5_list.append(keyword)\r\n",
    "                if len(keywords) == 4:\r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                    elif count == 2:\r\n",
    "                        keyword3_list.append(keyword)\r\n",
    "                    elif count == 3:\r\n",
    "                        keyword4_list.append(keyword)\r\n",
    "                        keyword5_list.append(\"\")\r\n",
    "                if len(keywords) == 3:\r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                    elif count == 2:\r\n",
    "                        keyword3_list.append(keyword)\r\n",
    "                        keyword4_list.append(\"\")\r\n",
    "                        keyword5_list.append(\"\")\r\n",
    "                elif len(keywords) == 2: \r\n",
    "                    if count == 0:\r\n",
    "                        keyword1_list.append(keyword)\r\n",
    "                    elif count == 1:\r\n",
    "                        keyword2_list.append(keyword)\r\n",
    "                        keyword3_list.append(\"\")\r\n",
    "                        keyword4_list.append(\"\")\r\n",
    "                        keyword5_list.append(\"\")\r\n",
    "                elif len(keywords) == 1:\r\n",
    "                    keyword1_list.append(keyword)\r\n",
    "                    keyword2_list.append(\"\")\r\n",
    "                    keyword3_list.append(\"\")\r\n",
    "                    keyword4_list.append(\"\")\r\n",
    "                    keyword5_list.append(\"\")\r\n",
    "\r\n",
    "# --Vars--\r\n",
    "date_list = []\r\n",
    "activities_date_list = []\r\n",
    "names_list = []\r\n",
    "websites_list = []\r\n",
    "locations_list = []\r\n",
    "buying_stage_list = []\r\n",
    "profile_fit_list = []\r\n",
    "account_reach_list = []\r\n",
    "keyword1_list = []\r\n",
    "keyword2_list = []\r\n",
    "keyword3_list = []\r\n",
    "keyword4_list = []\r\n",
    "keyword5_list = []\r\n",
    "comments_list = []\r\n",
    "users_count_list = []\r\n",
    "watchguard_visitors_list = []\r\n",
    "watchguard_links_list = []\r\n",
    "\r\n",
    "\r\n",
    "# --Main-code--\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    path = os.getcwd()\r\n",
    "    html_files = glob.glob(os.path.join(path, \"*.html\"))\r\n",
    "    html_files += glob.glob(os.path.join(path, \"*.htm\"))\r\n",
    "    print(\"Found\", len(html_files), \"HTML files\")\r\n",
    "\r\n",
    "    for url in html_files:\r\n",
    "        # print(url)\r\n",
    "        scrap_email(url)\r\n",
    "\r\n",
    "    for name in names_list:\r\n",
    "        date_list.append(dt.datetime.today().strftime(\"%d-%b-%Y\"))\r\n",
    "\r\n",
    "    dict = {\r\n",
    "        \"Date added\": date_list,\r\n",
    "        \"Activity date\": activities_date_list,\r\n",
    "        \"Name\": names_list,\r\n",
    "        \"Website\": websites_list,\r\n",
    "        \"Location\": locations_list,\r\n",
    "        \"Buying stage\": buying_stage_list,\r\n",
    "        \"Profile fit\": profile_fit_list,\r\n",
    "        \"Account reach\": account_reach_list,\r\n",
    "        \"Watchguard visitors\": watchguard_visitors_list,\r\n",
    "        \"Watchguard links\": watchguard_links_list,\r\n",
    "        \"Keyword1\": keyword1_list,\r\n",
    "        \"Keyword2\": keyword2_list,\r\n",
    "        \"Keyword3\": keyword3_list,\r\n",
    "        \"Keyword4\": keyword4_list,\r\n",
    "        \"Keyword5\": keyword5_list,\r\n",
    "        \"Comment\": comments_list,\r\n",
    "        \"Users\": users_count_list,\r\n",
    "    }\r\n",
    "\r\n",
    "    df_data = pd.DataFrame(dict).sort_values(by=\"Users\")\r\n",
    "    searchfor = [\"school\", \"schools\", \"education\"]\r\n",
    "    df_data_schools = df_data[df_data[\"Name\"].str.contains('|'.join(searchfor), na=False, case=False)].drop_duplicates(keep=False) # Separeting schools from rest\r\n",
    "    df_data = pd.concat([df_data, df_data_schools]).drop_duplicates(keep=False)\r\n",
    "    df_keywords1 = df_data.filter(['Activity date', 'Keyword1'], axis=1).rename(columns = {'Keyword1':'Keywords' }) # Creating new DF and renaming Keyword1 column\r\n",
    "    df_keywords2 = df_data.filter(['Activity date', 'Keyword2'], axis=1).rename(columns = {'Keyword2':'Keywords' })\r\n",
    "    df_keywords3 = df_data.filter(['Activity date', 'Keyword3'], axis=1).rename(columns = {'Keyword3':'Keywords' })\r\n",
    "    df_keywords4 = df_data.filter(['Activity date', 'Keyword4'], axis=1).rename(columns = {'Keyword4':'Keywords' })\r\n",
    "    df_keywords5 = df_data.filter(['Activity date', 'Keyword5'], axis=1).rename(columns = {'Keyword5':'Keywords' })\r\n",
    "    df_keywords = pd.concat([df_keywords1, df_keywords2, df_keywords3, df_keywords4, df_keywords5]) # Merging all keywordsX into want DF\r\n",
    "    df_keywords = df_keywords[df_keywords[\"Keywords\"].astype(bool)].sort_values(\"Activity date\", ascending=False) # Droping empty cells in \"Keywords\" and sorting\r\n",
    "    pivot_keywords = pd.pivot_table(df_keywords, index=\"Keywords\", aggfunc='count').rename(columns = {'Activity date':'Count' }).sort_values(by=\"Count\", ascending=False)\r\n",
    "\r\n",
    "    with pd.ExcelWriter(path + \"/6sense_master_file.xlsx\") as writer:  # Saving data to file \r\n",
    "        df_data.to_excel(writer, sheet_name=\"Data\", index=False)\r\n",
    "        df_data_schools.to_excel(writer, sheet_name=\"Data_schools\", index=False)\r\n",
    "        pivot_keywords.to_excel(writer, sheet_name=\"Keywords_pivot\")\r\n",
    "        df_keywords.to_excel(writer, sheet_name=\"Keywords\", index=False)\r\n",
    "    print(\"File saved\")\r\n",
    "df_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 57 HTML files\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24608/1137031069.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Users\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0msearchfor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"school\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"schools\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"education\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m     \u001b[0mdf_data_schools\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'|'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearchfor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Separeting schools from rest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m     \u001b[0mdf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_data_schools\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mdf_keywords1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Activity date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Keyword1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'Keyword1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Keywords'\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Creating new DF and renaming Keyword1 column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6056\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"inplace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6057\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ignore_index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6058\u001b[1;33m         \u001b[0mduplicated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6060\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6194\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6195\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6197\u001b[0m         ids = get_group_index(\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6167\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6168\u001b[1;33m             \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6169\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         codes, uniques = factorize_array(\n\u001b[0m\u001b[0;32m    762\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m     uniques, codes = table.factorize(\n\u001b[0m\u001b[0;32m    564\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m     )\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.13 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "8065859a666a0a35ff186cc2b2b1d9fd6755a5e815cd2155f24ca932ca25e802"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}